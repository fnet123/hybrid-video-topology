\chapter{Test Cases}\label{chp:test-cases}

To narrow down the problem scope a little, I'll define some test cases we can work on, and assume that if a solution can efficiently serve these cases, it can serve most others as well. A summary of the test cases are given in \autoref{tab:test-cases}. Note that these are intended to be hard cases, with at least one node being more significantly more constrained than the others. Thus, failure to pass these tests do not necessarily imply that the solution is useless, only that there are cases where it'll fail, or perform sub-optimally. \autoref{fig:test-cases} illustrates the test cases graphically with the all the inter-node latencies.

Are there any trivial cases that can be ignored? As long as there's only two people in a conversation, and they have fairly low latency between each other and sufficient bandwidth, peer-to-peer is the optimal choice in all cases. Initially, it might seem like this would indeed be the case in all conversations with two participants, and not just the good-bandwidth, small-latency onces. However, this is not the case. To illustrate why, consider a conversation between two people, one in Europe and one in Asia. The \gls{rtt} between them is ~350ms. They both have fairly acceptable bandwidth, with 3Mbps each, which should be plenty to sustain an acceptable video link between them. This might not be the case, as the bandwidth between them is far more limited due to the long distance and many hops through publicly routed networks, which yields high probability of packet loss and jitter. But if each of the peers has a data center of a distributed VPS provider nearby, to which they can utilize their full bandwidth, this limitation might be overcome. These distributed VPS providers tend to have established high-quality connections between their own data centers, backed by \glspl{sla} and much higher bandwidths than available to private entities.

The available bandwidth between the two data centers is thus far greater than what can be achieved directly between the two peers. Because of this, their video link can be improved by routing their traffic through both data centers, thus enabling each peer to utilize the full bandwidth of their connection.\footnote{This is backed by a simple experiment, using DigitalOcean as our VPS provider. From a 100Mbit university connection in Norway, sustained data rates to their Singapore data center varied greatly, measuring 90kBps, 3,7MBps, 1,9MBps and 2,58MBps for each test. However, from their Amsterdam data center, a consistent throughput of 24,6MBps was measured}. The latency is however close to unchanged from routing through the data centers, only sustained bandwidth between the peers is improved (and probably less packet loss and jitter).

The test cases are not extensive, but should cover enough corner cases to be able to highlight the pros and cons of the different topologies. The examples cover the low-latency, few peers conversations; the bandwidth-challenged cases; the high-latency conversations; and the very heterogeneous device conversations, where one or more party is severely challenged in terms of either bandwidth or latency.

We assume that the back-end networks are not saturated, and that each user is bandwidth-constrained only by their own connection. By extension, the maximum bandwidth attainable between any pair of nodes in our network is the lesser of the upload bandwidth of the sending party and the download bandwidth of the receiving party. However, latency has to be defined for any pair of the nodes in the network, as this is mostly determined by their geographical location in relation to each other.

\begin{center}
    \captionof{table}{Summary of Test Cases}
    \label{tab:test-cases}
    \begin{tabular}{| l | l | p{7cm} |}
    \hline
    \textbf{Case name} & $\textbf{n}$ & \textbf{Description} \\ \hline
    Traveller & 3 & Two people with decent connections between them, one remote with high latency and severely restricted bandwidth to the others. \\ \hline
    Standup & 4 & Two people on desktop machines with wired connections, one laptop and one tablet on WiFi. \\ \hline
    Friends & 7 & Group split in two locations, each subgroup having short latencies internally, but larger latencies to the other group. Heterogenous bandwidths across the board. \\ \hline
    \end{tabular}
\end{center}
\todo{What is n?}
\todo{Restructure into subsections?}

How realistic are these cases? According to the appear.in data set in \autoref{chp:appear.in-usage}, conversation frequency exponentially decays as a function of conversation size, making the majority of conversations between two people. These conversations were not prioritized for the test cases, as it's easier to make hard test cases with larger conversations. And there's an asymmetry here, browsers that manage to deliver service under hard conditions in larger conversations are likely to ace hard conversations between two people, but the inverse is not necessarily true. No data was found on common inter-node latencies in conversations, thus we have no data to support whether the latencies in the test cases are realistic. If services start monitoring these metrics and combine them with bitrate analysis, they can estimate in which conversations they have unsatisfied users, and could add those conversations as future test cases.


\begin{figure}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics{test-case-traveller}
        \subcaption{Test case ``traveller''.}\label{fig:test-case-traveller}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics{test-case-standup}
        \caption{Test case ``standup''}\label{fig:test-case-standup}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{test-case-friends}
        \caption{Test case ``friends''}\label{fig:test-case-friends}
    \end{subfigure}
    \caption{The different test cases}
    \label{fig:test-cases}
\end{figure}
