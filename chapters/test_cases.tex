\chapter{Test Cases}\label{chp:test-cases}

Instead of trying to optimize all possible combinations of bandwidths and latencies that occur in the wild, I'll define some test cases here that we can work on. The assumption is that if an approach can be found to efficiently serve these cases, it can serve most others as well.

A summary of the test cases are given in \autoref{tab:test-cases}. Note that these are intended to be hard cases, with at least one node being significantly more constrained than the others. Thus, failure to pass these tests do not necessarily imply that the solution is useless, only that there are cases where it'll fail, or perform sub-optimally. \autoref{fig:test-cases} illustrates the test cases graphically with the all the inter-node latencies.

Are there any trivial cases that can be ignored? As long as there's only two people in a conversation, and they have fairly low latency between each other and sufficient bandwidth, peer-to-peer is the optimal choice in all cases. Initially, it might seem like this would indeed be the case in all conversations with two participants, and not just the good-bandwidth, small-latency onces. However, this is not the case. To illustrate why, consider a conversation between two people, one in Europe and one in Asia. They both have fairly acceptable bandwidth, with 3 Mbps each, which should be plenty to sustain an acceptable video link between them. This might not be the case, as the link quality between them is far more limited due to the long distance and many hops through publicly routed networks, which yields high probability of packet loss and jitter.

However, if both peers have a data center of a distributed VPS provider nearby, to which they can fully utilize their connection, this limitation might be overcome. These distributed VPS providers tend to have established high-quality connections between their own data centers backed by \glspl{sla}, which ensures a link quality far greater than what's available to private entities. Because of this, the two peers can improve their video link by routing their traffic through both data centers.\footnote{This is backed by a simple experiment, using DigitalOcean as our VPS provider. From a 100 Mbps university connection in Norway, sustained data rates to their Singapore data center varied greatly, measuring 720 kbps, 29.6 Mbps, 15.2 Mbps and 20.64 Mbps for each test. However, from their Amsterdam data center, a consistent throughput of 196.8 Mbps was measured to Singapore, and between Amsterdam and the university a consistent 89.6 Mbps.}. The latency is however close to unchanged from routing through the data centers, only sustained bandwidth between the peers is improved (and probably less packet loss and jitter).

The test cases are not extensive, but should cover enough corner cases to be able to highlight if services have any issues in constrained environments. The examples cover the low-latency, few peers conversations; the bandwidth-challenged cases; the high-latency conversations; and the very heterogeneous device conversations, where some nodes are severely challenged in terms of either bandwidth or latency compared to the rest.

We assume that the back-end networks are not saturated, and that each user is bandwidth-constrained only by their own connection. By extension, the maximum bandwidth attainable between any pair of nodes in our network is the lesser of the upload bandwidth of the sending party and the download bandwidth of the receiving party. However, latency has to be defined for any pair of the nodes in the network, as this is mostly determined by their geographical location in relation to each other.

\begin{center}
    \captionof{table}{Summary of Test Cases. $n$ is the conversation size.}
    \label{tab:test-cases}
    \begin{tabular}{| l | l | p{7cm} |}
    \hline
    \textbf{Case name} & $\textbf{n}$ & \textbf{Description} \\ \hline
    Traveller & 3 & Two people with decent connections between them, one remote with high latency and severely restricted bandwidth to the others. \\ \hline
    Standup & 4 & Two people on desktop machines with wired connections, one laptop and one tablet on WiFi. \\ \hline
    Friends & 7 & Group split in two locations, each subgroup having short latencies internally, but larger latencies to the other group. Heterogeneous bandwidths across the board. \\ \hline
    \end{tabular}
\end{center}

How realistic are these cases? The appear.in data set in \autoref{chp:appear.in-usage} shows that conversation frequency exponentially decays as a function of conversation size. More than half of the observed conversations are between two people. These conversations were not prioritized for the test cases, as it's easier to make hard test cases with larger conversations. And there's an asymmetry here, browsers that manage to deliver service under hard conditions in larger conversations are likely to ace hard conversations between two people, but the inverse is not necessarily true. No data was found on common inter-node latencies in conversations, thus we have no data to support whether the latencies in the test cases are realistic. If services start monitoring these metrics and combine them with bitrate analysis, they can extract under-performing conversation types based on QoS and add those conversations as future test cases.


\begin{figure}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics{test-case-traveller}
        \subcaption{Test case ``traveller''.}\label{fig:test-case-traveller}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics{test-case-standup}
        \caption{Test case ``standup''}\label{fig:test-case-standup}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{test-case-friends}
        \caption{Test case ``friends''}\label{fig:test-case-friends}
    \end{subfigure}
    \caption{The different test cases. A node with ($x$/$y$) indicates $x$ Mbps downlink and $y$ Mbps uplink capacity.}
    \label{fig:test-cases}
\end{figure}
